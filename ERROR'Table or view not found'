root@74ad7202f647:/home/workspace# python etl.py
Ivy Default Cache set to: /root/.ivy2/cache
The jars for the packages stored in: /root/.ivy2/jars
:: loading settings :: url = jar:file:/opt/spark-2.4.3-bin-hadoop2.7/jars/ivy-2.4.0.jar!/org/apache/ivy/core/settings/ivysettings.xml
org.apache.hadoop#hadoop-aws added as a dependency
:: resolving dependencies :: org.apache.spark#spark-submit-parent-e0266a1e-ae31-4365-b6d9-a2a86b0c1530;1.0
        confs: [default]
        found org.apache.hadoop#hadoop-aws;2.7.0 in central
        found org.apache.hadoop#hadoop-common;2.7.0 in central
        found org.apache.hadoop#hadoop-annotations;2.7.0 in central
        found com.google.guava#guava;11.0.2 in central
        found com.google.code.findbugs#jsr305;3.0.0 in central
        found commons-cli#commons-cli;1.2 in central
        found org.apache.commons#commons-math3;3.1.1 in central
        found xmlenc#xmlenc;0.52 in central
        found commons-httpclient#commons-httpclient;3.1 in central
        found commons-logging#commons-logging;1.1.3 in central
        found commons-codec#commons-codec;1.4 in central
        found commons-io#commons-io;2.4 in central
        found commons-net#commons-net;3.1 in central
        found commons-collections#commons-collections;3.2.1 in central
        found javax.servlet#servlet-api;2.5 in central
        found org.mortbay.jetty#jetty;6.1.26 in central
        found org.mortbay.jetty#jetty-util;6.1.26 in central
        found com.sun.jersey#jersey-core;1.9 in central
        found com.sun.jersey#jersey-json;1.9 in central
        found org.codehaus.jettison#jettison;1.1 in central
        found com.sun.xml.bind#jaxb-impl;2.2.3-1 in central
        found javax.xml.bind#jaxb-api;2.2.2 in central
        found javax.xml.stream#stax-api;1.0-2 in central
        found javax.activation#activation;1.1 in central
        found org.codehaus.jackson#jackson-core-asl;1.9.13 in central
        found org.codehaus.jackson#jackson-mapper-asl;1.9.13 in central
        found org.codehaus.jackson#jackson-jaxrs;1.9.13 in central
        found org.codehaus.jackson#jackson-xc;1.9.13 in central
        found com.sun.jersey#jersey-server;1.9 in central
        found asm#asm;3.2 in central
        found log4j#log4j;1.2.17 in central
        found net.java.dev.jets3t#jets3t;0.9.0 in central
        found org.apache.httpcomponents#httpclient;4.2.5 in central
        found org.apache.httpcomponents#httpcore;4.2.5 in central
        found com.jamesmurty.utils#java-xmlbuilder;0.4 in central
        found commons-lang#commons-lang;2.6 in central
        found commons-configuration#commons-configuration;1.6 in central
        found commons-digester#commons-digester;1.8 in central
        found commons-beanutils#commons-beanutils;1.7.0 in central
        found commons-beanutils#commons-beanutils-core;1.8.0 in central
        found org.slf4j#slf4j-api;1.7.10 in central
        found org.apache.avro#avro;1.7.4 in central
        found com.thoughtworks.paranamer#paranamer;2.3 in central
        found org.xerial.snappy#snappy-java;1.0.4.1 in central
        found org.apache.commons#commons-compress;1.4.1 in central
        found org.tukaani#xz;1.0 in central
        found com.google.protobuf#protobuf-java;2.5.0 in central
        found com.google.code.gson#gson;2.2.4 in central
        found org.apache.hadoop#hadoop-auth;2.7.0 in central
        found org.apache.directory.server#apacheds-kerberos-codec;2.0.0-M15 in central
        found org.apache.directory.server#apacheds-i18n;2.0.0-M15 in central
        found org.apache.directory.api#api-asn1-api;1.0.0-M20 in central
        found org.apache.directory.api#api-util;1.0.0-M20 in central
        found org.apache.zookeeper#zookeeper;3.4.6 in central
        found org.slf4j#slf4j-log4j12;1.7.10 in central
        found io.netty#netty;3.6.2.Final in central
        found org.apache.curator#curator-framework;2.7.1 in central
        found org.apache.curator#curator-client;2.7.1 in central
        found com.jcraft#jsch;0.1.42 in central
        found org.apache.curator#curator-recipes;2.7.1 in central
        found org.apache.htrace#htrace-core;3.1.0-incubating in central
        found javax.servlet.jsp#jsp-api;2.1 in central
        found jline#jline;0.9.94 in central
        found junit#junit;4.11 in central
        found org.hamcrest#hamcrest-core;1.3 in central
        found com.fasterxml.jackson.core#jackson-databind;2.2.3 in central
        found com.fasterxml.jackson.core#jackson-annotations;2.2.3 in central
        found com.fasterxml.jackson.core#jackson-core;2.2.3 in central
        found com.amazonaws#aws-java-sdk;1.7.4 in central
        found joda-time#joda-time;2.12.1 in central
        [2.12.1] joda-time#joda-time;[2.2,)
:: resolution report :: resolve 5438ms :: artifacts dl 125ms
        :: modules in use:
        asm#asm;3.2 from central in [default]
        com.amazonaws#aws-java-sdk;1.7.4 from central in [default]
        com.fasterxml.jackson.core#jackson-annotations;2.2.3 from central in [default]
        com.fasterxml.jackson.core#jackson-core;2.2.3 from central in [default]
        com.fasterxml.jackson.core#jackson-databind;2.2.3 from central in [default]
        com.google.code.findbugs#jsr305;3.0.0 from central in [default]
        com.google.code.gson#gson;2.2.4 from central in [default]
        com.google.guava#guava;11.0.2 from central in [default]
        com.google.protobuf#protobuf-java;2.5.0 from central in [default]
        com.jamesmurty.utils#java-xmlbuilder;0.4 from central in [default]
        com.jcraft#jsch;0.1.42 from central in [default]
        com.sun.jersey#jersey-core;1.9 from central in [default]
        com.sun.jersey#jersey-json;1.9 from central in [default]
        com.sun.jersey#jersey-server;1.9 from central in [default]
        com.sun.xml.bind#jaxb-impl;2.2.3-1 from central in [default]
        com.thoughtworks.paranamer#paranamer;2.3 from central in [default]
        commons-beanutils#commons-beanutils;1.7.0 from central in [default]
        commons-beanutils#commons-beanutils-core;1.8.0 from central in [default]
        commons-cli#commons-cli;1.2 from central in [default]
        commons-codec#commons-codec;1.4 from central in [default]
        commons-collections#commons-collections;3.2.1 from central in [default]
        commons-configuration#commons-configuration;1.6 from central in [default]
        commons-digester#commons-digester;1.8 from central in [default]
        commons-httpclient#commons-httpclient;3.1 from central in [default]
        commons-io#commons-io;2.4 from central in [default]
        commons-lang#commons-lang;2.6 from central in [default]
        commons-logging#commons-logging;1.1.3 from central in [default]
        commons-net#commons-net;3.1 from central in [default]
        io.netty#netty;3.6.2.Final from central in [default]
        javax.activation#activation;1.1 from central in [default]
        javax.servlet#servlet-api;2.5 from central in [default]
        javax.servlet.jsp#jsp-api;2.1 from central in [default]
        javax.xml.bind#jaxb-api;2.2.2 from central in [default]
        javax.xml.stream#stax-api;1.0-2 from central in [default]
        jline#jline;0.9.94 from central in [default]
        joda-time#joda-time;2.12.1 from central in [default]
        junit#junit;4.11 from central in [default]
        log4j#log4j;1.2.17 from central in [default]
        net.java.dev.jets3t#jets3t;0.9.0 from central in [default]
        org.apache.avro#avro;1.7.4 from central in [default]
        org.apache.commons#commons-compress;1.4.1 from central in [default]
        org.apache.commons#commons-math3;3.1.1 from central in [default]
        org.apache.curator#curator-client;2.7.1 from central in [default]
        org.apache.curator#curator-framework;2.7.1 from central in [default]
        org.apache.curator#curator-recipes;2.7.1 from central in [default]
        org.apache.directory.api#api-asn1-api;1.0.0-M20 from central in [default]
        org.apache.directory.api#api-util;1.0.0-M20 from central in [default]
        org.apache.directory.server#apacheds-i18n;2.0.0-M15 from central in [default]
        org.apache.directory.server#apacheds-kerberos-codec;2.0.0-M15 from central in [default]
        org.apache.hadoop#hadoop-annotations;2.7.0 from central in [default]
        org.apache.hadoop#hadoop-auth;2.7.0 from central in [default]
        org.apache.hadoop#hadoop-aws;2.7.0 from central in [default]
        org.apache.hadoop#hadoop-common;2.7.0 from central in [default]
        org.apache.htrace#htrace-core;3.1.0-incubating from central in [default]
        org.apache.httpcomponents#httpclient;4.2.5 from central in [default]
        org.apache.httpcomponents#httpcore;4.2.5 from central in [default]
        org.apache.zookeeper#zookeeper;3.4.6 from central in [default]
        org.codehaus.jackson#jackson-core-asl;1.9.13 from central in [default]
        org.codehaus.jackson#jackson-jaxrs;1.9.13 from central in [default]
        org.codehaus.jackson#jackson-mapper-asl;1.9.13 from central in [default]
        org.codehaus.jackson#jackson-xc;1.9.13 from central in [default]
        org.codehaus.jettison#jettison;1.1 from central in [default]
        org.hamcrest#hamcrest-core;1.3 from central in [default]
        org.mortbay.jetty#jetty;6.1.26 from central in [default]
        org.mortbay.jetty#jetty-util;6.1.26 from central in [default]
        org.slf4j#slf4j-api;1.7.10 from central in [default]
        org.slf4j#slf4j-log4j12;1.7.10 from central in [default]
        org.tukaani#xz;1.0 from central in [default]
        org.xerial.snappy#snappy-java;1.0.4.1 from central in [default]
        xmlenc#xmlenc;0.52 from central in [default]
        ---------------------------------------------------------------------
        |                  |            modules            ||   artifacts   |
        |       conf       | number| search|dwnlded|evicted|| number|dwnlded|
        ---------------------------------------------------------------------
        |      default     |   70  |   1   |   0   |   0   ||   70  |   0   |
        ---------------------------------------------------------------------

:: problems summary ::
:::: ERRORS
        SERVER ERROR: Bad Gateway url=https://dl.bintray.com/spark-packages/maven/joda-time/joda-time/maven-metadata.xml

        SERVER ERROR: Bad Gateway url=https://dl.bintray.com/spark-packages/maven/joda-time/joda-time/

        SERVER ERROR: Bad Gateway url=https://dl.bintray.com/spark-packages/maven/joda-time/joda-time/


:: USE VERBOSE OR DEBUG MESSAGE LEVEL FOR MORE DETAILS
:: retrieving :: org.apache.spark#spark-submit-parent-e0266a1e-ae31-4365-b6d9-a2a86b0c1530
        confs: [default]
        0 artifacts copied, 70 already retrieved (0kB/59ms)
22/11/20 06:28:44 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
Traceback (most recent call last):                                                                                
  File "/opt/spark-2.4.3-bin-hadoop2.7/python/pyspark/sql/utils.py", line 63, in deco
    return f(*a, **kw)
  File "/opt/spark-2.4.3-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py", line 328, in get_return_value
py4j.protocol.Py4JJavaError: An error occurred while calling o27.sql.
: org.apache.spark.sql.AnalysisException: Table or view not found: log_data; line 14 pos 4
        at org.apache.spark.sql.catalyst.analysis.package$AnalysisErrorAt.failAnalysis(package.scala:47)
        at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$lookupTableFromCatalog(Analyzer.scala:733)
        at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveRelation(Analyzer.scala:685)
        at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$8.applyOrElse(Analyzer.scala:715)
        at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$8.applyOrElse(Analyzer.scala:708)
        at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$apply$1.apply(AnalysisHelper.scala:90)
        at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$apply$1.apply(AnalysisHelper.scala:90)
        at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:70)
        at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:89)
        at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:86)
        at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:194)
        at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$class.resolveOperatorsUp(AnalysisHelper.scala:86)
        at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUp(LogicalPlan.scala:29)
        at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$1.apply(AnalysisHelper.scala:87)
        at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$1.apply(AnalysisHelper.scala:87)
        at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:326)
        at org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:187)
        at org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:324)
        at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:87)
        at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:86)
        at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:194)
        at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$class.resolveOperatorsUp(AnalysisHelper.scala:86)
        at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUp(LogicalPlan.scala:29)
        at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$1.apply(AnalysisHelper.scala:87)
        at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$1.apply(AnalysisHelper.scala:87)
        at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:326)
        at org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:187)
        at org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:324)
        at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:87)
        at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:86)
        at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:194)
        at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$class.resolveOperatorsUp(AnalysisHelper.scala:86)
        at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUp(LogicalPlan.scala:29)
        at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$1.apply(AnalysisHelper.scala:87)
        at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$1.apply(AnalysisHelper.scala:87)
        at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:326)
        at org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:187)
        at org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:324)
        at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:87)
        at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:86)
        at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:194)
        at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$class.resolveOperatorsUp(AnalysisHelper.scala:86)
        at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUp(LogicalPlan.scala:29)
        at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$1.apply(AnalysisHelper.scala:87)
        at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$1.apply(AnalysisHelper.scala:87)
        at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:326)
        at org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:187)
        at org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:324)
        at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:87)
        at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:86)
        at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:194)
        at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$class.resolveOperatorsUp(AnalysisHelper.scala:86)
        at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUp(LogicalPlan.scala:29)
        at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:708)
        at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:654)
        at org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1$$anonfun$apply$1.apply(RuleExecutor.scala:87)
        at org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1$$anonfun$apply$1.apply(RuleExecutor.scala:84)
        at scala.collection.LinearSeqOptimized$class.foldLeft(LinearSeqOptimized.scala:124)
        at scala.collection.immutable.List.foldLeft(List.scala:84)
        at org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1.apply(RuleExecutor.scala:84)
        at org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1.apply(RuleExecutor.scala:76)
        at scala.collection.immutable.List.foreach(List.scala:392)
        at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:76)
        at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:127)
        at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:121)
        at org.apache.spark.sql.catalyst.analysis.Analyzer$$anonfun$executeAndCheck$1.apply(Analyzer.scala:106)
        at org.apache.spark.sql.catalyst.analysis.Analyzer$$anonfun$executeAndCheck$1.apply(Analyzer.scala:105)
        at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:201)
        at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:105)
        at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:57)
        at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:55)
        at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:47)
        at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:78)
        at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:642)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
        at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
        at py4j.Gateway.invoke(Gateway.java:282)
        at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
        at py4j.commands.CallCommand.execute(CallCommand.java:79)
        at py4j.GatewayConnection.run(GatewayConnection.java:238)
        at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.sql.catalyst.analysis.NoSuchTableException: Table or view 'log_data' not found in database 'default';
        at org.apache.spark.sql.catalyst.catalog.ExternalCatalog$class.requireTableExists(ExternalCatalog.scala:48)
        at org.apache.spark.sql.catalyst.catalog.InMemoryCatalog.requireTableExists(InMemoryCatalog.scala:45)
        at org.apache.spark.sql.catalyst.catalog.InMemoryCatalog.getTable(InMemoryCatalog.scala:326)
        at org.apache.spark.sql.catalyst.catalog.ExternalCatalogWithListener.getTable(ExternalCatalogWithListener.scala:138)
        at org.apache.spark.sql.catalyst.catalog.SessionCatalog.lookupRelation(SessionCatalog.scala:706)
        at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$lookupTableFromCatalog(Analyzer.scala:730)
        ... 83 more


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "etl.py", line 122, in <module>
    main()
  File "etl.py", line 118, in main
    process_log_data(spark, input_data, output_data)
  File "etl.py", line 107, in process_log_data
    """)
  File "/opt/spark-2.4.3-bin-hadoop2.7/python/pyspark/sql/session.py", line 767, in sql
    return DataFrame(self._jsparkSession.sql(sqlQuery), self._wrapped)
  File "/opt/spark-2.4.3-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 1257, in __call__
  File "/opt/spark-2.4.3-bin-hadoop2.7/python/pyspark/sql/utils.py", line 69, in deco
    raise AnalysisException(s.split(': ', 1)[1], stackTrace)
pyspark.sql.utils.AnalysisException: 'Table or view not found: log_data; line 14 pos 4'
